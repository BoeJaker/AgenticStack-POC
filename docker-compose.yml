version: '3.8'

# =============================================================================
# AGENTIC AI INFRASTRUCTURE STACK
# =============================================================================
# A comprehensive Docker Compose setup for building advanced AI agent systems
# with database backends, vector stores, graph databases, workflow automation,
# monitoring, and observability tools.
#
# Usage:
#   Start:              docker compose up
#   With helpers:       docker compose -f docker-compose.yml -f ./dev/docker-compose.dev.yml up
#   Stop:               docker compose down
#   Destroy:            docker compose -f docker-compose.yml -f ./dev/docker-compose.dev.yml down -v --remove-orphans
#   Reset everything:   ./reset.sh
# =============================================================================

services:
  # =============================================================================
  # CORE INFRASTRUCTURE
  # =============================================================================
  
  # Traefik - Reverse Proxy & Load Balancer
  # Automatically routes traffic to containers based on labels and provides
  # SSL termination, service discovery, and load balancing
  traefik:
    image: traefik:v2.10
    container_name: traefik
    command:
      - "--api.insecure=true"                    # Enable dashboard (for dev)
      - "--providers.docker=true"                # Use Docker as provider
      - "--providers.docker.exposedbydefault=false"  # Only expose labeled containers
      - "--entrypoints.web.address=:80"          # HTTP entry point
      - "--entrypoints.websecure.address=:443"   # HTTPS entry point
      - "--certificatesresolvers.myresolver.acme.tlschallenge=true"  # Let's Encrypt SSL
      - "--certificatesresolvers.myresolver.acme.email=you@example.com"
      - "--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json"

      # Custom SSL certificates (commented out)
      # - "--entrypoints.websecure.http.tls=true"
      # - "--entrypoints.websecure.http.tls.certificates[0].certFile=/certs/llm.int.crt"
      # - "--entrypoints.websecure.http.tls.certificates[0].keyFile=/certs/llm.int.key"
    ports:
      - "80:80"     # HTTP
      - "443:443"   # HTTPS
      - "8083:8080" # Dashboard
    volumes:
      - "./letsencrypt:/letsencrypt"              # SSL certificates storage
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Docker socket for service discovery
      - ./traefik/llm.int.crt:/certs/llm.int.crt # Custom SSL cert (optional)
      - ./traefik/llm.int.key:/certs/llm.int.key # Custom SSL key (optional)
    networks:
      - agentic-network

  # =============================================================================
  # SUPABASE - PostgreSQL-based Backend-as-a-Service
  # Complete authentication, database, storage, and real-time features
  # =============================================================================

  # Supabase Studio - Web-based Database Administration Interface
  # Provides a GUI for managing databases, tables, authentication, and storage
  studio:
    container_name: supabase-studio
    image: supabase/studio:2025.06.30-sha-6f5982d
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "fetch('http://studio:3000/api/platform/profile').then((r) => {if (r.status !== 200) throw new Error(r.status)})"
        ]
      timeout: 10s
      interval: 5s
      retries: 3
    depends_on:
      analytics:
        condition: service_healthy
    environment:
      # Core Supabase connections
      STUDIO_PG_META_URL: http://meta:8080
      POSTGRES_PASSWORD: ${SUPABASE_DB_PASSWORD}

      # Studio configuration
      DEFAULT_ORGANIZATION_NAME: ${STUDIO_DEFAULT_ORGANIZATION}
      DEFAULT_PROJECT_NAME: ${STUDIO_DEFAULT_PROJECT}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}

      # API endpoints and keys
      SUPABASE_URL: http://kong:8000
      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL}
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      AUTH_JWT_SECRET: ${JWT_SECRET}

      # Analytics integration
      LOGFLARE_PRIVATE_ACCESS_TOKEN: ${LOGFLARE_PRIVATE_ACCESS_TOKEN}
      LOGFLARE_URL: http://analytics:4000
      NEXT_PUBLIC_ENABLE_LOGS: true
      NEXT_ANALYTICS_BACKEND_PROVIDER: postgres  # Use Postgres for analytics
    ports:
      - 54321:3000  # Studio web interface
    networks:
      - agentic-network

  # Kong - API Gateway
  # Routes and manages API requests between clients and Supabase services
  # Provides authentication, rate limiting, and request transformation
  kong:
    container_name: supabase-kong
    image: kong:2.8.1
    restart: unless-stopped
    ports:
      - ${KONG_HTTP_PORT}:8000/tcp   # HTTP API gateway
      - ${KONG_HTTPS_PORT}:8443/tcp  # HTTPS API gateway
    volumes:
      - ./volumes/api/kong.yml:/home/kong/temp.yml:ro,z  # Kong configuration template
    depends_on:
      analytics:
        condition: service_healthy
    environment:
      KONG_DATABASE: "off"                       # Use declarative config
      KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml
      KONG_DNS_ORDER: LAST,A,CNAME
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k   # Buffer settings for large requests
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
      # API keys for authentication
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      DASHBOARD_USERNAME: ${DASHBOARD_USERNAME}
      DASHBOARD_PASSWORD: ${DASHBOARD_PASSWORD}
    # Process template and start Kong
    entrypoint: bash -c 'eval "echo \"$$(cat ~/temp.yml)\"" > ~/kong.yml && /docker-entrypoint.sh kong docker-start'
    networks:
      - agentic-network

  # GoTrue - Authentication Service
  # Handles user registration, login, JWT tokens, and social auth providers
  auth:
    container_name: supabase-auth
    image: supabase/gotrue:v2.177.0
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://localhost:9999/health"
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    volumes:
      - /supabase/init:/docker-entrypoint-initdb.d
    depends_on:
      supabase-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      # Service configuration
      GOTRUE_API_HOST: 0.0.0.0
      GOTRUE_API_PORT: 9999
      API_EXTERNAL_URL: ${API_EXTERNAL_URL}

      # Database connection
      GOTRUE_DB_DRIVER: postgres
      GOTRUE_DB_DATABASE_URL: postgres://supabase_auth_admin:${SUPABASE_DB_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

      # Site configuration
      GOTRUE_SITE_URL: ${SITE_URL}
      GOTRUE_URI_ALLOW_LIST: ${ADDITIONAL_REDIRECT_URLS}
      GOTRUE_DISABLE_SIGNUP: ${DISABLE_SIGNUP}

      # JWT configuration
      GOTRUE_JWT_ADMIN_ROLES: service_role
      GOTRUE_JWT_AUD: authenticated
      GOTRUE_JWT_DEFAULT_GROUP_NAME: authenticated
      GOTRUE_JWT_EXP: ${JWT_EXPIRY}
      GOTRUE_JWT_SECRET: ${JWT_SECRET}

      # Email authentication
      GOTRUE_EXTERNAL_EMAIL_ENABLED: ${ENABLE_EMAIL_SIGNUP}
      GOTRUE_EXTERNAL_ANONYMOUS_USERS_ENABLED: ${ENABLE_ANONYMOUS_USERS}
      GOTRUE_MAILER_AUTOCONFIRM: ${ENABLE_EMAIL_AUTOCONFIRM}
      GOTRUE_MAILER_EXTERNAL_HOSTS: kong,llm.int,localhost

      # SMTP configuration for email sending
      GOTRUE_SMTP_ADMIN_EMAIL: ${SMTP_ADMIN_EMAIL}
      GOTRUE_SMTP_HOST: ${SMTP_HOST}
      GOTRUE_SMTP_PORT: ${SMTP_PORT}
      GOTRUE_SMTP_USER: ${SMTP_USER}
      GOTRUE_SMTP_PASS: ${SMTP_PASS}
      GOTRUE_SMTP_SENDER_NAME: ${SMTP_SENDER_NAME}
      
      # Email template URLs
      GOTRUE_MAILER_URLPATHS_INVITE: ${MAILER_URLPATHS_INVITE}
      GOTRUE_MAILER_URLPATHS_CONFIRMATION: ${MAILER_URLPATHS_CONFIRMATION}
      GOTRUE_MAILER_URLPATHS_RECOVERY: ${MAILER_URLPATHS_RECOVERY}
      GOTRUE_MAILER_URLPATHS_EMAIL_CHANGE: ${MAILER_URLPATHS_EMAIL_CHANGE}

      # Phone authentication
      GOTRUE_EXTERNAL_PHONE_ENABLED: ${ENABLE_PHONE_SIGNUP}
      GOTRUE_SMS_AUTOCONFIRM: ${ENABLE_PHONE_AUTOCONFIRM}
      
      # Auth hooks (commented examples for custom logic)
      # GOTRUE_HOOK_CUSTOM_ACCESS_TOKEN_ENABLED: "true"
      # GOTRUE_HOOK_CUSTOM_ACCESS_TOKEN_URI: "pg-functions://postgres/public/custom_access_token_hook"
    networks:
      - agentic-network

  # PostgREST - Automatic REST API for PostgreSQL
  # Generates REST endpoints directly from database schema with fine-grained permissions
  rest:
    container_name: supabase-rest
    image: postgrest/postgrest:v12.2.12
    restart: unless-stopped
    depends_on:
      supabase-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      # Database connection as authenticator role
      PGRST_DB_URI: postgres://authenticator:${SUPABASE_DB_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      PGRST_DB_SCHEMAS: ${PGRST_DB_SCHEMAS}        # Which schemas to expose
      PGRST_DB_ANON_ROLE: anon                     # Default role for anonymous access
      PGRST_JWT_SECRET: ${JWT_SECRET}              # JWT verification
      PGRST_DB_USE_LEGACY_GUCS: "false"
      PGRST_APP_SETTINGS_JWT_SECRET: ${JWT_SECRET}
      PGRST_APP_SETTINGS_JWT_EXP: ${JWT_EXPIRY}
    command: ["postgrest"]
    networks:
      - agentic-network

  # Realtime - WebSocket server for real-time database changes
  # Broadcasts database changes, presence, and custom events to connected clients
  realtime:
    container_name: realtime-dev.supabase-realtime  # Name pattern required for tenant ID parsing
    image: supabase/realtime:v2.34.47
    restart: unless-stopped
    depends_on:
      supabase-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "-sSfL",
          "--head",
          "-o",
          "/dev/null",
          "-H",
          "Authorization: Bearer ${ANON_KEY}",
          "http://localhost:4000/api/tenants/realtime-dev/health"
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      PORT: 4000
      # Database connection
      DB_HOST: ${POSTGRES_HOST}
      DB_PORT: ${POSTGRES_PORT}
      DB_USER: supabase_admin
      DB_PASSWORD: ${SUPABASE_DB_PASSWORD}
      DB_NAME: ${POSTGRES_DB}
      DB_AFTER_CONNECT_QUERY: 'SET search_path TO _realtime'
      DB_ENC_KEY: supabaserealtime
      # JWT and security
      API_JWT_SECRET: ${JWT_SECRET}
      SECRET_KEY_BASE: ${SECRET_KEY_BASE}
      # Erlang clustering configuration
      ERL_AFLAGS: -proto_dist inet_tcp
      DNS_NODES: "''"
      RLIMIT_NOFILE: "10000"
      # Application settings
      APP_NAME: realtime
      SEED_SELF_HOST: true
      RUN_JANITOR: true                            # Clean up old connections
    networks:
      - agentic-network

  # Storage - File storage service with S3-compatible API
  # Handles file uploads, downloads, and transformations with fine-grained access control
  storage:
    container_name: supabase-storage
    image: supabase/storage-api:v1.25.7
    restart: unless-stopped
    volumes:
      - ./volumes/storage:/var/lib/storage:z       # File storage location
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://storage:5000/status"
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    depends_on:
      supabase-db:
        condition: service_healthy
      rest:
        condition: service_started
      imgproxy:
        condition: service_started
    environment:
      # API keys
      ANON_KEY: ${ANON_KEY}
      SERVICE_KEY: ${SERVICE_ROLE_KEY}
      # Service endpoints
      POSTGREST_URL: http://rest:3000
      PGRST_JWT_SECRET: ${JWT_SECRET}
      # Database connection
      DATABASE_URL: postgres://supabase_storage_admin:${SUPABASE_DB_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      # Storage configuration
      FILE_SIZE_LIMIT: 52428800                    # 50MB max file size
      STORAGE_BACKEND: file                        # Use local file storage
      FILE_STORAGE_BACKEND_PATH: /var/lib/storage
      TENANT_ID: stub
      REGION: stub
      GLOBAL_S3_BUCKET: stub
      # Image transformation
      ENABLE_IMAGE_TRANSFORMATION: "true"
      IMGPROXY_URL: http://imgproxy:5001
    networks:
      - agentic-network

  # ImgProxy - High-performance image processing service
  # Handles image resizing, optimization, and format conversion on-the-fly
  imgproxy:
    container_name: supabase-imgproxy
    image: darthsim/imgproxy:v3.8.0
    restart: unless-stopped
    volumes:
      - ./volumes/storage:/var/lib/storage:z       # Access to storage files
    healthcheck:
      test: ["CMD", "imgproxy", "health"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      IMGPROXY_BIND: ":5001"
      IMGPROXY_LOCAL_FILESYSTEM_ROOT: /
      IMGPROXY_USE_ETAG: "true"                    # Enable caching
      IMGPROXY_ENABLE_WEBP_DETECTION: ${IMGPROXY_ENABLE_WEBP_DETECTION}
    networks:
      - agentic-network

  # Meta - Database schema management API
  # Provides REST API for database schema operations, table management, and metadata
  meta:
    container_name: supabase-meta
    image: supabase/postgres-meta:v0.91.0
    restart: unless-stopped
    depends_on:
      supabase-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      PG_META_PORT: 8080
      PG_META_DB_HOST: ${POSTGRES_HOST}
      PG_META_DB_PORT: ${POSTGRES_PORT}
      PG_META_DB_NAME: ${POSTGRES_DB}
      PG_META_DB_USER: supabase_admin
      PG_META_DB_PASSWORD: ${SUPABASE_DB_PASSWORD}
    networks:
      - agentic-network

  # Edge Functions - Serverless function runtime
  # Executes TypeScript/JavaScript functions at the edge with Deno runtime
  functions:
    container_name: supabase-edge-functions
    image: supabase/edge-runtime:v1.69.6
    restart: unless-stopped
    volumes:
      - ./volumes/functions:/home/deno/functions:Z  # Function source code
    depends_on:
      analytics:
        condition: service_healthy
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}
      SUPABASE_DB_URL: postgresql://postgres:${SUPABASE_DB_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      VERIFY_JWT: "${FUNCTIONS_VERIFY_JWT}"        # Verify JWT tokens in functions
    command:
      [
        "start",
        "--main-service",
        "/home/deno/functions/main"
      ]
    networks:
      - agentic-network

  # Analytics - Log collection and analytics service (Logflare)
  # Collects, processes, and stores logs and analytics data from all Supabase services
  analytics:
    container_name: supabase-analytics
    image: supabase/logflare:1.14.2
    restart: unless-stopped
    ports:
      - 4000:4000
    # BigQuery support (commented)
    # volumes:
    #   - type: bind
    #     source: ${PWD}/gcloud.json
    #     target: /opt/app/rel/logflare/bin/gcloud.json
    #     read_only: true
    healthcheck:
      test: ["CMD", "curl", "http://localhost:4000/health"]
      timeout: 5s
      interval: 5s
      retries: 10
    depends_on:
      supabase-db:
        condition: service_healthy
    environment:
      LOGFLARE_NODE_HOST: 127.0.0.1
      # Database connection for metadata
      DB_USERNAME: ${POSTGRES_USER}
      DB_DATABASE: _supabase
      DB_HOSTNAME: ${POSTGRES_HOST}
      DB_PORT: ${POSTGRES_PORT}
      DB_PASSWORD: ${SUPABASE_DB_PASSWORD}
      DB_SCHEMA: _analytics
      # API tokens
      LOGFLARE_PUBLIC_ACCESS_TOKEN: ${LOGFLARE_PUBLIC_ACCESS_TOKEN}
      LOGFLARE_PRIVATE_ACCESS_TOKEN: ${LOGFLARE_PRIVATE_ACCESS_TOKEN}
      # Configuration
      LOGFLARE_SINGLE_TENANT: true
      LOGFLARE_SUPABASE_MODE: true
      LOGFLARE_MIN_CLUSTER_SIZE: 1

      # PostgreSQL backend for analytics (default)
      POSTGRES_BACKEND_URL: postgresql://supabase_admin:${SUPABASE_DB_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/_supabase
      POSTGRES_BACKEND_SCHEMA: _analytics
      LOGFLARE_FEATURE_FLAG_OVERRIDE: multibackend=true
      
      # BigQuery backend (commented)
      # GOOGLE_PROJECT_ID: ${GOOGLE_PROJECT_ID}
      # GOOGLE_PROJECT_NUMBER: ${GOOGLE_PROJECT_NUMBER}
    networks:
      - agentic-network

  # =============================================================================
  # DATABASE LAYER
  # =============================================================================

  # PostgreSQL - Primary relational database
  # Enhanced with Supabase extensions for auth, storage, and real-time features
  supabase-db:
    container_name: supabase-db
    image: supabase/postgres:15.8.1.060
    restart: unless-stopped
    volumes:
      # Initialization scripts
      - ./volumes/db/realtime.sql:/docker-entrypoint-initdb.d/migrations/99-realtime.sql:Z
      - ./volumes/db/webhooks.sql:/docker-entrypoint-initdb.d/init-scripts/98-webhooks.sql:Z
      - ./volumes/db/roles.sql:/docker-entrypoint-initdb.d/init-scripts/99-roles.sql:Z
      - ./volumes/db/jwt.sql:/docker-entrypoint-initdb.d/init-scripts/99-jwt.sql:Z
      - ./volumes/db/_supabase.sql:/docker-entrypoint-initdb.d/migrations/97-_supabase.sql:Z
      - ./volumes/db/logs.sql:/docker-entrypoint-initdb.d/migrations/99-logs.sql:Z
      - ./volumes/db/pooler.sql:/docker-entrypoint-initdb.d/migrations/99-pooler.sql:Z
      # Data persistence
      - ./volumes/db/data:/var/lib/postgresql/data:Z
      - db-config:/etc/postgresql-custom               # Config persistence
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres", "-h", "localhost"]
      interval: 5s
      timeout: 5s
      retries: 10
    depends_on:
      vector:
        condition: service_healthy
    environment:
      POSTGRES_HOST: /var/run/postgresql
      PGPORT: ${POSTGRES_PORT}
      POSTGRES_PORT: ${POSTGRES_PORT}
      PGPASSWORD: ${SUPABASE_DB_PASSWORD}
      POSTGRES_PASSWORD: ${SUPABASE_DB_PASSWORD}
      PGDATABASE: ${POSTGRES_DB}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      # JWT configuration for auth
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXP: ${JWT_EXPIRY}
    networks:
      - agentic-network
    command:
      [
        "postgres",
        "-c",
        "config_file=/etc/postgresql/postgresql.conf",
        "-c",
        "log_min_messages=fatal"                     # Reduce log noise
      ]

  # Vector - Log aggregation and routing
  # Collects logs from Docker containers and routes them to analytics service
  vector:
    container_name: supabase-vector
    image: timberio/vector:0.28.1-alpine
    restart: unless-stopped
    volumes:
      - ./volumes/logs/vector.yml:/etc/vector/vector.yml:ro,z
      - ${DOCKER_SOCKET_LOCATION}:/var/run/docker.sock:ro,z
    healthcheck:
      test:
        [
          "CMD",
          "wget",
          "--no-verbose",
          "--tries=1",
          "--spider",
          "http://vector:9001/health"
        ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      LOGFLARE_PUBLIC_ACCESS_TOKEN: ${LOGFLARE_PUBLIC_ACCESS_TOKEN}
    networks:
      - agentic-network
    command: ["--config", "/etc/vector/vector.yml"]
    security_opt:
      - "label=disable"

  # Supavisor - PostgreSQL connection pooler and proxy
  # Manages database connections efficiently and provides load balancing
  supavisor:
    container_name: supabase-pooler
    image: supabase/supavisor:2.5.7
    restart: unless-stopped
    ports:
      - ${POSTGRES_PORT}:5432                       # PostgreSQL protocol
      - ${POOLER_PROXY_PORT_TRANSACTION}:6543      # Transaction pooling
    volumes:
      - ./volumes/pooler/pooler.exs:/etc/pooler/pooler.exs:ro,z
    healthcheck:
      test:
        [
          "CMD",
          "curl",
          "-sSfL",
          "--head",
          "-o",
          "/dev/null",
          "http://127.0.0.1:4000/api/health"
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      supabase-db:
        condition: service_healthy
      analytics:
        condition: service_healthy
    environment:
      PORT: 4000
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_PASSWORD: ${SUPABASE_DB_PASSWORD}
      DATABASE_URL: ecto://${POSTGRES_USER}:${SUPABASE_DB_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/_supabase
      CLUSTER_POSTGRES: true
      SECRET_KEY_BASE: ${SECRET_KEY_BASE}
      VAULT_ENC_KEY: ${VAULT_ENC_KEY}
      API_JWT_SECRET: ${JWT_SECRET}
      METRICS_JWT_SECRET: ${JWT_SECRET}
      REGION: local
      ERL_AFLAGS: -proto_dist inet_tcp
      # Pooling configuration
      POOLER_TENANT_ID: ${POOLER_TENANT_ID}
      POOLER_DEFAULT_POOL_SIZE: ${POOLER_DEFAULT_POOL_SIZE}
      POOLER_MAX_CLIENT_CONN: ${POOLER_MAX_CLIENT_CONN}
      POOLER_POOL_MODE: transaction
      DB_POOL_SIZE: ${POOLER_DB_POOL_SIZE}
    command:
      [
        "/bin/sh",
        "-c",
        "/app/bin/migrate && /app/bin/supavisor eval \"$$(cat /etc/pooler/pooler.exs)\" && /app/bin/server"
      ]
    networks:
      - agentic-network

  # =============================================================================
  # VECTOR DATABASES - For AI/ML embeddings and similarity search
  # =============================================================================

  # ChromaDB - Open-source vector database
  # Stores and queries high-dimensional embeddings for semantic search and RAG
  chroma:
    image: chromadb/chroma:1.0.22.dev17
    container_name: chroma
    ports:
      - "8008:8000"
    environment:
      CHROMA_DB_IMPL: sqlite                        # Use SQLite for storage
      CHROMA_SERVER_HOST: 0.0.0.0
      # External embedding configuration using Ollama
      CHROMA_DEFAULT_EMBEDDING_FUNCTION: ollama
      OLLAMA_API_BASE: http://ollama:11435          # Connect to local Ollama
      OLLAMA_MODEL: "nomic-embed-text"              # Embedding model
    volumes:
      - chroma_data:/chroma/db                      # Persistent storage
    networks:
      - agentic-network

  # Weaviate - Vector database with built-in vectorization
  # Provides GraphQL API and automatic vectorization of objects
  weaviate:
    image: semitechnologies/weaviate:1.19.3
    container_name: weaviate
    ports:
      - "8010:8080"   # REST API
      - "8009:8081"   # gRPC
    environment:
      QUERY_DEFAULTS_LIMIT: 20
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: /var/lib/weaviate
      # Ollama integration (commented)
      # DEFAULT_VECTORIZER_MODULE: text2vec-ollama
      # ENABLE_MODULES: text2vec-ollama
      # OLLAMA_URL: http://ollama:11435
      # OLLAMA_MODEL: nomic-embed-text:latest
    volumes:
      - weaviate-data:/var/lib/weaviate
    networks:
      - agentic-network

  # =============================================================================
  # GRAPH DATABASES - For knowledge graphs and relationship modeling
  # =============================================================================

  # Neo4j - Leading graph database
  # Stores and queries complex relationships, perfect for knowledge graphs
  neo4j-stack:
    image: neo4j:5.13-community
    container_name: neo4j-stack
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD}
      NEO4J_PLUGINS: '["apoc", "graph-data-science"]'  # Essential plugins
      # APOC configuration for data import/export
      NEO4J_apoc_export_file_enabled: true
      NEO4J_apoc_import_file_enabled: true
      NEO4J_apoc_import_file_use__neo4j__config: true
      NEO4J_dbms_security_procedures_unrestricted: apoc.*,gds.*
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
      - neo4j-import:/var/lib/neo4j/import
      - neo4j-plugins:/plugins
    ports:
      - "7475:7474"  # HTTP (Browser interface)
      - "7688:7687"  # Bolt protocol
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.neo4j.rule=Host(`${DOMAIN}`) && PathPrefix(`/neo4j`)"
      - "traefik.http.services.neo4j.loadbalancer.server.port=7474"

  # Grafiti Knowledge Graph (commented example)
  # Custom knowledge graph implementation
  # graphiti-kg:
  #   build:
  #     context: ./graphiti
  #     dockerfile: Dockerfile
  #   container_name: graphiti-kg
  #   depends_on:
  #     - neo4j-stack
  #     - supabase-db
  #   environment:
  #     NEO4J_URI: bolt://neo4j-stack:7688
  #     NEO4J_USERNAME: neo4j
  #     NEO4J_PASSWORD: ${NEO4J_PASSWORD}
  #     POSTGRES_URL: postgres://supabase_admin:${SUPABASE_DB_PASSWORD}@supabase-db:5432/postgres
  #   volumes:
  #     - grafiti-data:/app/data
  #   ports:
  #     - 8000:8000
  #   networks:
  #     - agentic-network
  #   labels:
  #     - "traefik.enable=true"
  #     - "traefik.http.routers.graphiti.rule=Host(`${DOMAIN}`) && PathPrefix(`/graphiti`)"
  #     - "traefik.http.services.graphiti.loadbalancer.server.port=9999"
  
  # =============================================================================
  # WORKFLOW & AUTOMATION PLATFORMS
  # =============================================================================

  # n8n - Visual Workflow Automation Platform
  # Low-code/no-code automation tool for connecting APIs and services
  # Enables building complex workflows with a drag-and-drop interface
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    command: start --tunnel                         # Enable tunneling for webhooks
    environment:
      # Basic configuration
      N8N_SECURE_COOKIE: false
      N8N_HOST: ${DOMAIN}
      N8N_PORT: 5678
      N8N_PATH: /n8n
      N8N_PROTOCOL: https
      NODE_ENV: production
      
      # Webhook configuration
      # WEBHOOK_URL: https://${DOMAIN}/n8n/
      GENERIC_TIMEZONE: ${TIMEZONE}
      
      # PostgreSQL database configuration
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: supabase-db
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: postgres              # Using main Supabase DB
      DB_POSTGRESDB_USER: supabase_admin
      DB_POSTGRESDB_SCHEMA: n8n                     # Separate schema for n8n
      DB_POSTGRESDB_PASSWORD: ${SUPABASE_DB_PASSWORD}
    volumes:
      - n8n-data:/home/node/.n8n                    # Workflow and credential storage
      - /proc:/host_proc:ro                         # Host process info (for monitoring)
    ports:
      - 5678:5678
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.n8n.rule=PathPrefix(`/n8n`)"
      - "traefik.http.routers.n8n.entrypoints=websecure"
      - "traefik.http.routers.n8n.tls.certresolver=myresolver"
      - "traefik.http.services.n8n.loadbalancer.server.port=5678"
      - "traefik.http.middlewares.n8n-stripprefix.stripprefix.prefixes=/n8n"
      - "traefik.http.routers.n8n.middlewares=n8n-stripprefix"

  # Flowise - Visual AI Flow Builder
  # Low-code platform for building LangChain flows and AI applications
  # Drag-and-drop interface for creating chatbots and AI workflows
  flowise:
    image: flowiseai/flowise:latest
    container_name: flowise
    environment:
      PORT: 3000
      HOST: 0.0.0.0
      # Local file-based storage paths
      DATABASE_PATH: /opt/flowise/.flowise
      APIKEY_PATH: /opt/flowise/.flowise
      SECRETKEY_PATH: /opt/flowise/.flowise
      LOG_LEVEL: info
      LOG_PATH: /opt/flowise/.flowise/logs
    volumes:
      - flowise-data:/opt/flowise/.flowise          # Persistent storage for flows and configs
    ports:
      - "3000:3000"
    networks:
      - agentic-network
    labels:
      - "traefik.http.routers.flowise.rule=PathPrefix(`/flowise`)"
      - "traefik.http.middlewares.flowise-stripprefix.stripprefix.prefixes=/flowise"
      - "traefik.http.routers.flowise.middlewares=flowise-stripprefix"
      - "traefik.http.services.flowise.loadbalancer.server.port=3000"

  # =============================================================================
  # USER INTERFACE LAYER
  # =============================================================================

  # Open WebUI - ChatGPT-style web interface for local LLMs
  # Modern web interface for interacting with Ollama and other LLM providers
  # Features chat history, model switching, and custom prompts
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    environment:
      # Path configuration for reverse proxy
      OPEN_WEBUI_ROOT_PATH: /webui
      # LLM backend connection
      OLLAMA_BASE_URL: http://ollama:11434
      # Security
      WEBUI_SECRET_KEY: ${WEBUI_SECRET_KEY}
      # PostgreSQL database for chat history and user data
      DATABASE_URL: postgresql://supabase_admin:${SUPABASE_DB_PASSWORD}@${SUPABASE_DB_HOST}:5432/postgres?&options=-csearch_path%3Dwebui
    volumes:
      - open-webui-data:/app/backend/data           # Application data storage
    depends_on:
      - supabase-db
      - ollama
    ports:
      - 8081:8080
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.webui.rule=Host(`${DOMAIN}`) && PathPrefix(`/webui`)"
      - "traefik.http.services.webui.loadbalancer.server.port=8080"

  # =============================================================================
  # LLM INFRASTRUCTURE - Large Language Model services and tools
  # =============================================================================

  # Ollama - Local LLM runtime
  # Runs large language models locally with GPU acceleration support
  # Provides OpenAI-compatible API for various models (Llama, Mistral, etc.)
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    volumes:
      - ollama-data:/root/.ollama                   # Model storage and cache
    environment:
      OLLAMA_HOST: 0.0.0.0                         # Listen on all interfaces
    ports:
      - 11435:11434                                # API endpoint
    networks:
      - agentic-network
    # GPU support (uncomment if you have NVIDIA GPU)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # OpenAI API Shim - Compatibility layer
  # Adapts Ollama API to be fully compatible with OpenAI API format
  # Allows existing OpenAI-based applications to work with local models
  ollama-openai-shim:
    build: ./openai-api-shim                       # Custom middleware service
    container_name: ollama-openai-shim
    ports:
      - "8080:8080"
    depends_on:
      - ollama
    networks:
      - agentic-network

  # Knowledge Graph Integration Shim
  # Middleware that provides knowledge graph storage and retrieval capabilities
  # Connects LLM responses with graph database for enhanced reasoning
  ollama-knowledge-graph-shim:
    build: ./knowledge-shim                        # Custom middleware service  
    container_name: ollama-knowledge-graph-shim
    ports:
      - "8080:8080"                                # Note: Same port as openai-shim (choose one)
    depends_on:
      - ollama
    networks:
      - agentic-network

# =============================================================================
  # AI MULTIMODAL SERVICES - Vision, Audio, and Document Processing
  # Advanced AI services for handling different types of media and content
  # =============================================================================

  # Stable Diffusion - Text-to-Image Generation
  # Generates high-quality images from text prompts using diffusion models
  # Provides web interface for interactive image creation and editing
  stable-diffusion:
    image: ghcr.io/ashawkey/stable-diffusion-webui-cpu:latest
    container_name: stable-diffusion
    restart: unless-stopped
    ports:
      - "7860:7860"                                 # Web interface
    volumes:
      - ./volumes/ai-services/stable-diffusion:/data  # Model storage and generated images
    environment:
      CLI_ARGS: --listen --port 7860 --no-half --use-cpu all  # CPU-optimized settings
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.stable-diffusion.rule=Host(`${DOMAIN}`) && PathPrefix(`/sd`)"
      - "traefik.http.middlewares.sd-stripprefix.stripprefix.prefixes=/sd"
      - "traefik.http.routers.stable-diffusion.middlewares=sd-stripprefix"
      - "traefik.http.services.stable-diffusion.loadbalancer.server.port=7860"

  # BLIP - Image Understanding and Captioning
  # Generates descriptive captions for images using vision-language models
  # Provides API for automated image analysis and content description
  blip:
    image: ghcr.io/suno-ai/blip:latest
    container_name: blip
    restart: unless-stopped
    ports:
      - "8001:8000"                                # REST API endpoint
    volumes:
      - ./volumes/ai-services/blip:/app/data       # Processing cache and models
    command: >
      python -m uvicorn blip_api:app --host 0.0.0.0 --port 8000
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.blip.rule=Host(`${DOMAIN}`) && PathPrefix(`/api/blip`)"
      - "traefik.http.services.blip.loadbalancer.server.port=8000"

  # YOLOv8 - Real-time Object Detection
  # Detects and classifies objects in images and video streams
  # Provides bounding boxes, confidence scores, and class labels
  yolov8:
    image: ultralytics/ultralytics:latest
    container_name: yolov8
    restart: unless-stopped
    ports:
      - "8003:8000"                                # Detection API
    command: >
      uvicorn ultralytics.server:app --host 0.0.0.0 --port 8000
    volumes:
      - ./volumes/ai-services/yolov8:/data         # Model weights and detection cache
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.yolov8.rule=Host(`${DOMAIN}`) && PathPrefix(`/api/detect`)"
      - "traefik.http.services.yolov8.loadbalancer.server.port=8000"

  # PaddleOCR - Optical Character Recognition
  # Extracts text from images and documents with high accuracy
  # Supports multiple languages and document formats
  paddleocr:
    image: ghcr.io/paddlepaddle/paddleocr:latest
    container_name: paddleocr
    restart: unless-stopped
    ports:
      - "8004:8080"                               # OCR processing API
    volumes:
      - ./volumes/ai-services/paddleocr:/app/data # OCR models and processing cache
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.paddleocr.rule=Host(`${DOMAIN}`) && PathPrefix(`/api/ocr`)"
      - "traefik.http.services.paddleocr.loadbalancer.server.port=8080"

  # Whisper - Speech-to-Text Transcription
  # Converts audio files and streams to text with high accuracy
  # Supports multiple languages and handles various audio formats
  whisper:
    image: ghcr.io/go-skynet/whisper-cpu:latest
    container_name: whisper
    restart: unless-stopped
    ports:
      - "8005:8000"                               # Transcription API
    environment:
      WHISPER_MODEL: base                         # Model size (tiny/base/small/medium/large)
    volumes:
      - ./volumes/ai-services/whisper:/app/data   # Model cache and audio processing
    command: >
      python -m faster_whisper.server --model $WHISPER_MODEL --host 0.0.0.0 --port 8000
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.whisper.rule=Host(`${DOMAIN}`) && PathPrefix(`/api/stt`)"
      - "traefik.http.services.whisper.loadbalancer.server.port=8000"

  # Piper - Text-to-Speech Synthesis
  # Converts text to natural-sounding speech with various voice options
  # High-quality neural TTS with low latency for real-time applications
  piper:
    image: rhasspy/piper:latest
    container_name: piper
    restart: unless-stopped
    ports:
      - "8006:8000"                               # TTS synthesis API
    volumes:
      - ./volumes/ai-services/piper:/data         # Voice models and audio cache
    command: >
      piper --server --host 0.0.0.0 --port 8000
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.piper.rule=Host(`${DOMAIN}`) && PathPrefix(`/api/tts`)"
      - "traefik.http.services.piper.loadbalancer.server.port=8000"

  # Text Embeddings Inference - Semantic Search Engine
  # Converts text to high-dimensional vectors for similarity search
  # Optimized for fast inference with sentence transformer models
  text-embeddings:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-latest
    container_name: text-embeddings
    restart: unless-stopped
    ports:
      - "8007:80"                                 # Embeddings API
    environment:
      MODEL_ID: sentence-transformers/all-MiniLM-L6-v2  # Lightweight but effective model
      MAX_BATCH_REQUESTS: 32                      # Batch processing optimization
      MAX_CONCURRENT_REQUESTS: 128               # Concurrent request handling
    volumes:
      - ./volumes/ai-services/embeddings:/data   # Model cache and embeddings storage
    networks:
      - agentic-network
    # Health check to ensure service is ready
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.embeddings.rule=Host(`${DOMAIN}`) && PathPrefix(`/api/embeddings`)"
      - "traefik.http.services.embeddings.loadbalancer.server.port=80"

  # Model Router & Load Balancer
  # Intelligent request routing between different model sizes based on complexity
  # Routes simple queries to fast models, complex queries to powerful models
  model-router:
    build:
      context: ./model-router
      dockerfile: Dockerfile
    container_name: model-router
    environment:
      LIGHT_MODEL_ENDPOINT: http://ollama:11434/api/generate     # Fast model for simple queries
      HEAVY_MODEL_ENDPOINT: http://ollama:11434/api/generate     # Powerful model for complex queries
      COMPLEXITY_THRESHOLD: ${COMPLEXITY_THRESHOLD:-0.7}        # Threshold for routing decisions
    depends_on:
      - ollama
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.model-router.rule=Host(`${DOMAIN}`) && PathPrefix(`/api/model`)"

  # =============================================================================
  # TOOL SERVERS - External tool integration for AI agents
  # =============================================================================

  # MCP (Model Context Protocol) Server
  # Standardized protocol for connecting AI models to external tools and data
  # Provides secure, controlled access to external resources
  mcp-server:
    build:
      context: ./mcp-server
      dockerfile: Dockerfile
    container_name: mcp-server
    environment:
      MCP_SERVER_PORT: 8000
      DATABASE_URL: postgres://mcp_user:${MCP_DB_PASSWORD}@supabase-db:5432/mcp
    volumes:
      - mcp-data:/app/data                          # Tool execution workspace
    depends_on:
      - supabase-db
    networks:
      - agentic-network

  # Generic Tool Server (commented example)
  # Custom tool server for additional capabilities
  # generic-tool-server:
  #   build:
  #     context: ./tool-server
  #     dockerfile: Dockerfile
  #   container_name: generic-tool-server
  #   environment:
  #     TOOL_SERVER_PORT: 8001
  #     DATABASE_URL: postgres://tools_user:${TOOLS_DB_PASSWORD}@supabase-db:5432/tools
  #   volumes:
  #     - tool-server-data:/app/data
  #     - ./langchain-code:/app/langchain           # Custom LangChain integrations
  #   depends_on:
  #     - supabase-db
  #   networks:
  #     - agentic-network

  # =============================================================================
  # AGENTIC CORE (commented example)
  # Advanced AI agent orchestration system
  # =============================================================================

  # agentic-core:
  #   build:
  #     context: ./agentic-core
  #     dockerfile: Dockerfile
  #   container_name: agentic-core
  #   environment:
  #     # Database connections
  #     DATABASE_URL: postgres://agent_user:${AGENT_DB_PASSWORD}@supabase-db:5432/agent
  #     NEO4J_URI: bolt://neo4j:7687
  #     NEO4J_USERNAME: neo4j
  #     NEO4J_PASSWORD: ${NEO4J_PASSWORD}
  #     
  #     # Service endpoints
  #     MODEL_ROUTER_URL: http://model-router:8000
  #     MCP_SERVER_URL: http://mcp-server:8000
  #     TOOL_SERVER_URL: http://generic-tool-server:8001
  #     GRAFITI_URL: http://grafiti-kg:8000
  #     N8N_WEBHOOK_URL: http://n8n:5678/webhook
  #     
  #     # Agent behavior configuration
  #     PROACTIVE_MODE: ${PROACTIVE_MODE:-true}          # Enable autonomous thinking
  #     THOUGHT_INTERVAL: ${THOUGHT_INTERVAL:-300}       # Think every 5 minutes
  #   volumes:
  #     - agentic-data:/app/data
  #     - ./langchain-code:/app/langchain               # Custom agent code
  #   depends_on:
  #     - supabase-db
  #     - neo4j-stack
  #     - model-router
  #     - graphiti-kg
  #   networks:
  #     - agentic-network
  #   labels:
  #     - "traefik.enable=true"
  #     - "traefik.http.routers.agentic-core.rule=Host(`${DOMAIN}`) && PathPrefix(`/api/agent`)"

  # Qdrant - High-performance vector search engine
  # Optimized for large-scale vector similarity search and filtering
  # Alternative to ChromaDB with better performance for production workloads
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    volumes:
      - qdrant-data:/qdrant/storage                 # Vector data storage
    ports:
      - "6333:6333"                                # REST API
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.qdrant.rule=Host(`${DOMAIN}`) && PathPrefix(`/qdrant`)"

  # =============================================================================
  # MONITORING, METRICS & OBSERVABILITY
  # Complete observability stack for monitoring the entire infrastructure
  # =============================================================================

  # Prometheus - Metrics collection and alerting system
  # Time-series database for collecting metrics from all services
  # Provides powerful query language (PromQL) for analyzing performance
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml  # Configuration
      - prometheus-data:/prometheus                 # Time-series data storage
    ports:
      - 9090:9090                                  # Web UI and API
      # Additional exporters (uncomment as needed):
      # - 9091:9091 # Pushgateway (push metrics instead of pull)
      # - 9093:9093 # Alertmanager (alert notifications)
      # - 9100:9100 # Node Exporter (system metrics)
      # - 9104:9104 # MySQL Exporter
      # - 9114:9114 # Elasticsearch Exporter
      # - 9115:9115 # Blackbox Exporter (endpoint monitoring)
      # - 9182:9182 # SNMP Exporter (network device monitoring)
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`${DOMAIN}`) && PathPrefix(`/prometheus`)"

  # Grafana - Metrics visualization and dashboarding
  # Creates beautiful dashboards for monitoring infrastructure health
  # Connects to Prometheus, Loki, and other data sources
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
    volumes:
      - grafana-data:/var/lib/grafana               # Dashboard and user data
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards    # Pre-built dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources  # Data source configs
    depends_on:
      - prometheus
    ports:
      - 3001:3000
    networks:
      - agentic-network
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.grafana.rule=Host(`${DOMAIN}`) && PathPrefix(`/grafana`)"

  # Loki - Log aggregation system
  # Horizontally scalable, multi-tenant log aggregation
  # Works seamlessly with Grafana for log visualization
   loki:
    image: grafana/loki:2.9.0
    container_name: loki
    volumes:
      - ./monitoring/loki/loki-config.yaml:/etc/loki/local-config.yaml
      - loki-data:/loki
    ports:
      - "3100:3100"
    networks:
      - agentic-network

  # Promtail - Log collection agent
  # Collects logs from files and Docker containers
  # Ships logs to Loki for centralized storage and analysis  # Update Promtail with proper configuration
  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
      - ./monitoring/promtail/config.yaml:/etc/promtail/config.yaml
    command: -config.file=/etc/promtail/config.yaml
    depends_on:
      - loki
    networks:
      - agentic-network

  # System metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    ports:
      - "9100:9100"
    networks:
      - agentic-network

  # PostgreSQL metrics
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://supabase_admin:${SUPABASE_DB_PASSWORD}@supabase-db:5432/postgres?sslmode=disable"
    ports:
      - "9187:9187"
    depends_on:
      - supabase-db
    networks:
      - agentic-network
  # =============================================================================
  # DEVELOPMENT & TUNNELING TOOLS
  # =============================================================================

  # Ngrok - Secure tunneling service
  # Exposes local services to the internet securely
  # Useful for webhook development and external API integration testing
  ngrok:
    image: ngrok/ngrok:latest
    command: https n8n:5678                        # Tunnel n8n for webhooks
    ports:
      - "4040:4040"                                # Web interface for tunnel management
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}         # Required for custom domains/features
    networks:
      - agentic-network

# =============================================================================
# NETWORK CONFIGURATION
# =============================================================================
networks:
  agentic-network:
    driver: bridge                                 # Internal Docker network for service communication

# =============================================================================
# PERSISTENT STORAGE VOLUMES
# =============================================================================
volumes:
  # Supabase volumes
  supabase-db-data:                               # PostgreSQL data
  db-config:                                      # PostgreSQL configuration
  
  # Graph database volumes  
  neo4j-data:                                     # Neo4j graph data
  neo4j-logs:                                     # Neo4j application logs
  neo4j-import:                                   # Data import directory
  neo4j-plugins:                                  # Neo4j plugins
  grafiti-data:                                   # Custom knowledge graph data
  
  # Workflow automation volumes
  n8n-data:                                       # n8n workflows and credentials
  flowise-data:                                   # Flowise AI flows and configurations
  
  # UI and LLM volumes
  open-webui-data:                               # Chat interface user data
  ollama-data:                                   # LLM models and cache
  
  # Tool and agent volumes
  mcp-data:                                      # MCP server tool data
  tool-server-data:                              # Generic tool server data
  agentic-data:                                  # Core agent system data
  
  # Monitoring volumes
  prometheus-data:                               # Metrics time-series data
  grafana-data:                                  # Dashboards and user preferences
  loki-data:

  # Vector database volumes
  qdrant-data:                                   # Vector embeddings storage
  chroma_data:                                   # ChromaDB vector storage
  weaviate-data:                                 # Weaviate vector and object storage